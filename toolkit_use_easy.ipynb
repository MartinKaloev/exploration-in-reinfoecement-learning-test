{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c06b79-362a-438f-8201-f7ffa748e731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 12:27:31.347651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-23 12:27:31.347678: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "User Current Version:- 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "0.15.7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "toolkit\n",
    "Usage:\n",
    "python3 *.py\n",
    "https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
    "\n",
    "# toolkit_for_exploration_in_RL_\n",
    "this is supporting toolking for the paper : Experiments Focused on Exploration in Deep Reinforcement Learning with doi: DOI: 10.1109/ISMSIT52890.2021.9604690\n",
    "\n",
    "\n",
    "This toolkit is create to ease experiments with RL-exploration\n",
    "options:\n",
    "1. Optional test described in the paper\n",
    "1.1. no restictricted exploration\n",
    "1.2. randomized explorarion\n",
    "1.3. artificial restrictions\n",
    "1.4 lead by teacher explorations\n",
    "2. options for custom size ANN\n",
    "3. options for custom sized buffer replay\n",
    "4. options for build in plots (visualizations of results)\n",
    "5. option for choosing size of training episodes and test episodes\n",
    "6. option for overestemation checking (described in the paper)\n",
    "\n",
    "BONUS: REALtime checking how advantage changes weights of the ANNs during training\n",
    "\n",
    "Do please e-mail at: kaloev_92@mail.ru \n",
    "\n",
    "If this toolkit may be usefull for you, used!!!!\n",
    "Citation of the paper will be much apriciated, \n",
    "Have a nice day dear reader. \n",
    "\n",
    "\n",
    "this is my ocena code updates ipynb\n",
    "===========\n",
    "IMPORTANT FOR VERSIONS\n",
    "keras , tf version - 2.6.0 ; do change into proper tensor version (shapes for 2.11 or v3)\n",
    "gym version 0.15.7\n",
    "\"\"\"\n",
    "import sys\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import time\n",
    "import random\n",
    "\n",
    "print(tf. __version__) \n",
    "print(keras.__version__)\n",
    "print(\"User Current Version:-\", sys.version)\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef608952-ed9f-4e29-9dc7-d3926eb2c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(2)\n",
      "State space: Box(4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 6\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "#env.seed(RANDOM_SEED)\n",
    "#np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Action Space: {}\".format(env.action_space))\n",
    "print(\"State space: {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c453dd-9d92-4516-8358-f67e9d2a03db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "to enter into custom setings press c or 1:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deffult settings used \n"
     ]
    }
   ],
   "source": [
    "# An episode a full game\n",
    "com=input(\"to enter into custom setings press c or 1: \")\n",
    "if com==\"c\" or com==\"1\":\n",
    "    print(\"custtom settings menu: \")\n",
    "    train_episodes = int(input(\"chose how many episode is whole test: \"))\n",
    "    ctr_ep= int(input(\"chose how many episode are spend in training \"))\n",
    "    buffer=int(input(\"buffer size, warning this will efect after how many action the ANN is updated: \"))\n",
    "    custom_deept_layers_actor= int( input(\"custom size of actor deppt, warning, choosing incorct dept may cause overfitting: \"))\n",
    "    custom_deept_layers_critic= int( input(\"custom size of critic deppt, warning, choosing incorct dept may cause overfitting: \"))\n",
    "    \n",
    "else:\n",
    "    print(\"deffult settings used \")\n",
    "    train_episodes = 90\n",
    "    ctr_ep=60\n",
    "    buffer=2\n",
    "    custom_deept_layers_actor=2\n",
    "    custom_deept_layers_critic=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf82c980-18dc-41a4-8051-1741a5b314ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_actor(state_shape, action_shape, func_,i=3):\n",
    "    \n",
    "    init = tf.keras.initializers.HeUniform()\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(124, input_shape=state_shape, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    for j in range(0, i):\n",
    "        model.add(keras.layers.Dense(112, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    " \n",
    "    model.add(keras.layers.Dense(action_shape, activation=func_ , kernel_initializer=init))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2736485-46ac-4e25-bf3a-89c6993d820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_critic(state_shape, output_shape,i=4):\n",
    "    \n",
    "    init = tf.keras.initializers.HeUniform()\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(124, input_shape=state_shape, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    for j in range(0, i):\n",
    "        model.add(keras.layers.Dense(112, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "\n",
    "    model.add(keras.layers.Dense(output_shape, activation='linear', kernel_initializer=init))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c09e9d-f632-40a0-808e-e2f454e78c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actor2(state_shape, action_shape):\n",
    "    \n",
    "    init = tf.keras.initializers.HeUniform()\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(124, input_shape=state_shape, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(12, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(action_shape, activation='softmax', kernel_initializer=init))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b68e55-c608-4d0b-8eab-df976fffd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting fature\n",
    "def plts(rewards,name_fig,r=\"Rewards\", e=\"Episodes\"):\n",
    "\tplt.xlabel(e)\n",
    "\tplt.ylabel(r)\n",
    "\tplt.title(name_fig)\n",
    "\tplt.plot(rewards)\n",
    "\t#plt.plot(ep)\n",
    "\t#plt.legend(loc=0)\n",
    "\tplt.savefig(name_fig) \n",
    "\tplt.show()      \n",
    "\n",
    "\n",
    "#add to check name oof off actions\n",
    "def savs(fl_name,rewards_list):\n",
    "    ff=open(fl_name+\".txt\",\"w\")\n",
    "    ff.write(str(rewards_list))\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4026d4de-e7de-41fc-ad86-61db9c21a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ctr_l):\n",
    "    actor_checkpoint_path = \"training_actor/actor_cp.ckpt\"\n",
    "    critic_checkpoint_path = \"training_critic/critic_cp.ckpt\"\n",
    "    actor_checkpoint_path2 = \"training_actor/actor_cp.hdf5\"\n",
    "    critic_checkpoint_path2 = \"training_critic/critic_cp.hdf5\"\n",
    "\n",
    "\n",
    "    \n",
    "    actor_checkpoint_path_ = \"training_actor_/actor_cp.ckpt\"\n",
    "    actor_checkpoint_path2_ = \"training_actor_/actor_cp.hdf5\"\n",
    "    \n",
    "\n",
    "    actor = create_actor(env.observation_space.shape, env.action_space.n, 'softmax', custom_deept_layers_actor)\n",
    "    actor.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "    actor_overest = create_actor(env.observation_space.shape, env.action_space.n, \"linear\" , custom_deept_layers_actor)\n",
    "    actor_overest.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "    critic = create_critic(env.observation_space.shape, 1 , custom_deept_layers_critic)\n",
    "    critic.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    actor2 = create_actor2(env.observation_space.shape, env.action_space.n)\n",
    "    actor2.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "    #add teacher ACTOR HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #saaves maybe\n",
    "    if os.path.exists('training_actor'):\n",
    "        actor.load_weights(actor_checkpoint_path)\n",
    "\n",
    "        critic.load_weights(critic_checkpoint_path)\n",
    "    \n",
    "    if os.path.exists('training_actor_'):\n",
    "        actor2.load_weights(actor_checkpoint_path_)\n",
    "        print(\"LOADED\")\n",
    "    else:\n",
    "        print(\"crash\")\n",
    " \n",
    "\n",
    "    #BUFFERS\n",
    "    rewards_=[]\n",
    "    rewards_2=[]\n",
    "    obs_=[]\n",
    "    advs_=[]\n",
    "    acts_=[]\n",
    "    long_advs_=[]\n",
    "    tds_=[]\n",
    "    acts_raw_=[]\n",
    "    over_left_=[]\n",
    "    over_rigght_=[]\n",
    "    #BUFFERS\n",
    "\n",
    "    for episode in range(train_episodes):\n",
    "        total_training_rewards = 0\n",
    "        action_c=0\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if True:\n",
    "                #DO NOT RENDER HERE IT . CRASH CODEOCEAN\n",
    "                #env.render()\n",
    "                pass\n",
    "\n",
    "            # model dims are (batch, env.observation_space.n)\n",
    "            # tensoers convers\n",
    "\n",
    "            observation_reshaped = tf.convert_to_tensor(observation)\n",
    "            observation_reshaped = tf.expand_dims(observation_reshaped,0)\n",
    "            action_probs = actor.predict(observation_reshaped).flatten()\n",
    "            action_probs2 = actor2.predict(observation_reshaped).flatten()\n",
    "\n",
    "            \n",
    "            \n",
    "            #action add custom\n",
    "            if ctr_l==0:\n",
    "                action =(np.argmax(action_probs))\n",
    "            elif ctr_l==2:\n",
    "                if episode < ctr_ep:\n",
    "                    if (observation[2] > .17):\n",
    "                        action=1\n",
    "                    else:\n",
    "                        action=(np.argmax(action_probs))\n",
    "                else:\n",
    "                    action=(np.argmax(action_probs))\n",
    "            elif ctr_l==1:\n",
    "                if episode < ctr_l:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action=(np.argmax(action_probs))\n",
    "            elif ctr_l==3:\n",
    "                if episode < ctr_l:\n",
    "                    action=(np.argmax(action_probs2))\n",
    "                else:\n",
    "                    action=(np.argmax(action_probs))\n",
    "            else:\n",
    "                print(\"CRASHED\")\n",
    "            \n",
    "\n",
    "            next_observation, reward, done, info = env.step(action)\n",
    "            next_observation_reshaped = tf.convert_to_tensor(next_observation)\n",
    "            next_observation_reshaped = tf.expand_dims(next_observation_reshaped,0)\n",
    "            \n",
    "\n",
    "            #add size here for train eps_\n",
    "            if (episode <ctr_ep):\n",
    "                value_curr = np.asscalar(np.array(critic.predict(observation_reshaped)))\n",
    "                value_next = np.asscalar(np.array(critic.predict(next_observation_reshaped)))\n",
    "\n",
    "            # calculation of A= (r+V(s') - V (s))\n",
    "                discount_factor = .7\n",
    "                Temp_Diff = reward + (1 - done) * discount_factor * value_next\n",
    "                advantage = Temp_Diff- value_curr\n",
    "            \n",
    "                advantage_reshaped = np.vstack([advantage])\n",
    "                TD_target = np.vstack([Temp_Diff])\n",
    "\n",
    "                #mid batch mormalisation traing for V*(s)\n",
    "                critic.train_on_batch(observation_reshaped, TD_target)\n",
    "\n",
    "                acts_raw_.append(action_probs)\n",
    "                obs_.append(observation)\n",
    "                acts_.append(action)\n",
    "                advs_.append(advantage)\n",
    "                tds_.append(Temp_Diff)\n",
    "                \n",
    "                if len(obs_)>buffer:\n",
    "\n",
    "                    #apply gradiotion and train ANNS\n",
    "                    actor.fit(np.array(obs_), np.array(acts_), sample_weight=np.array(advs_), epochs=10 ,verbose=0)\n",
    "                    critic.fit(np.array(obs_), np.array(tds_), epochs=10 ,verbose=0)\n",
    "\n",
    "\n",
    "                    #REAL TIME UPDATES features\n",
    "                    for i in range(len(obs_)):\n",
    "                        _saved_=obs_[i]\n",
    "                        _saved_ = tf.convert_to_tensor(_saved_)\n",
    "                        _saved_= tf.expand_dims(_saved_,0)\n",
    "                        updated_=actor.predict(_saved_)\n",
    "                        print(\"observation-f: \", np.round(obs_[i],3), \" pre update acts: \", np.round(acts_raw_[i],3),\" advantage used: \",np.round(advs_[i],2) , \" post update acts: \", np.round(updated_[0],3))\n",
    "                    \n",
    "                    \n",
    "                    obs_.clear()\n",
    "                    acts_.clear()\n",
    "                    advs_.clear()\n",
    "                    long_advs_.clear()\n",
    "                    tds_.clear()\n",
    "                    acts_raw_.clear()\n",
    "            \n",
    "            observation = next_observation\n",
    "            total_training_rewards += reward\n",
    "            action_c+=1\n",
    "\n",
    "            if episode > ctr_ep:\n",
    "                \n",
    "                #OVERESTEAMTION OBSERVATIONS FEATIRES\n",
    "                over_left=(actor_overest.predict(observation_reshaped).flatten())[0]\n",
    "                over_rigght=(actor_overest.predict(observation_reshaped).flatten())[1]\n",
    "\n",
    "                over_left_.append(over_left)\n",
    "                over_rigght_.append(over_rigght)\n",
    "\n",
    "            if done:\n",
    "                \n",
    "                print ( \"ep:\",episode ,\"act num:\", action_c  ,\"r:\", np.round(reward, 2), \"big r: \",total_training_rewards,\" adv: \",np.round(advantage, 2) ,\"act:\", np.round(action,2), \"s-facor: \", observation, \"act-space \", action )\n",
    "                \n",
    "                rewards_.append(total_training_rewards)\n",
    "                if episode >ctr_ep:\n",
    "\n",
    "                    actor_overest.set_weights(actor.get_weights())\n",
    "                    rewards_2.append(total_training_rewards)\n",
    "                    \n",
    "                    \n",
    " \n",
    "            \n",
    "\n",
    "\n",
    "    env.close()\n",
    "    if ctr_l==0:\n",
    "        flag_=\"no restriction\"\n",
    "    elif ctr_l ==1:\n",
    "        flag_=\"randomized moves\"\n",
    "    elif ctr_l ==2:\n",
    "        flag_=\"restriction\"\n",
    "    elif ctr_l ==3:\n",
    "        flag_=\"leaded by teacher\"\n",
    "\n",
    "    plts(rewards_,\"Rewards per episode \"+str(flag_))\n",
    "    plts(rewards_2,\"Rewards per episode_post chosing moves with \"+str(flag_))\n",
    "\n",
    "    plts(over_left_,\"Overestemation left \"+str(flag_),\"overestemation\", \"actions\")\n",
    "    plts(over_rigght_,\"Overestemation right \"+str(flag_), \"overestemations\", \"actions\")\n",
    "    #add plts for overestemations___\n",
    "\n",
    "    savs(\"full_\",rewards_)\n",
    "    savs(\"post_tr\",rewards_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc80c54-a151-4b50-90ea-0a5f4ce40068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter test rotine  \n",
      " 0 - no restriction run \n",
      " 1 - randomized exploration \n",
      " 2 - run with restrictions \n",
      " 3 - expl lead by teacher ANN :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 12:27:38.621601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-23 12:27:38.621628: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-23 12:27:38.621645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (636b3d74423a): /proc/driver/nvidia/version does not exist\n",
      "2022-12-23 12:27:38.622090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 124)               620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 112)               14000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 226       \n",
      "=================================================================\n",
      "Total params: 27,502\n",
      "Trainable params: 27,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 124)               620       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 112)               14000     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 226       \n",
      "=================================================================\n",
      "Total params: 27,502\n",
      "Trainable params: 27,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 12:27:38.912203: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:109: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "/opt/conda/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation-f:  [ 0.027  0.01  -0.013  0.003]  pre update acts:  [0.495 0.505]  advantage used:  0.97  post update acts:  [0.342 0.658]\n",
      "observation-f:  [ 0.028  0.206 -0.013 -0.294]  pre update acts:  [0.591 0.409]  advantage used:  0.94  post update acts:  [0.971 0.029]\n",
      "observation-f:  [ 0.032  0.011 -0.019 -0.005]  pre update acts:  [0.496 0.504]  advantage used:  1.17  post update acts:  [0.351 0.649]\n",
      "observation-f:  [ 0.032  0.206 -0.019 -0.304]  pre update acts:  [0.974 0.026]  advantage used:  -0.21  post update acts:  [0.986 0.014]\n",
      "observation-f:  [ 0.036  0.011 -0.025 -0.017]  pre update acts:  [0.375 0.625]  advantage used:  1.52  post update acts:  [0.144 0.856]\n",
      "observation-f:  [ 0.036  0.207 -0.026 -0.318]  pre update acts:  [0.977 0.023]  advantage used:  -0.09  post update acts:  [0.988 0.012]\n",
      "observation-f:  [ 0.04   0.012 -0.032 -0.034]  pre update acts:  [0.16 0.84]  advantage used:  0.93  post update acts:  [0.074 0.926]\n",
      "observation-f:  [ 0.041  0.208 -0.033 -0.336]  pre update acts:  [0.991 0.009]  advantage used:  0.23  post update acts:  [0.995 0.005]\n",
      "observation-f:  [ 0.045  0.013 -0.04  -0.054]  pre update acts:  [0.2 0.8]  advantage used:  0.17  post update acts:  [0.107 0.893]\n",
      "observation-f:  [ 0.045 -0.182 -0.041  0.226]  pre update acts:  [0.002 0.998]  advantage used:  0.37  post update acts:  [0.001 0.999]\n",
      "observation-f:  [ 0.041  0.014 -0.036 -0.079]  pre update acts:  [0.225 0.775]  advantage used:  0.52  post update acts:  [0.769 0.231]\n",
      "observation-f:  [ 0.042 -0.181 -0.038  0.202]  pre update acts:  [0.003 0.997]  advantage used:  0.06  post update acts:  [0.001 0.999]\n",
      "observation-f:  [ 0.038  0.015 -0.034 -0.103]  pre update acts:  [0.885 0.115]  advantage used:  0.07  post update acts:  [0.977 0.023]\n",
      "observation-f:  [ 0.038 -0.179 -0.036  0.179]  pre update acts:  [0.002 0.998]  advantage used:  0.6  post update acts:  [0.001 0.999]\n",
      "observation-f:  [ 0.035  0.016 -0.032 -0.125]  pre update acts:  [0.938 0.062]  advantage used:  0.16  post update acts:  [0.99 0.01]\n",
      "observation-f:  [ 0.035 -0.179 -0.035  0.158]  pre update acts:  [0.002 0.998]  advantage used:  -0.1  post update acts:  [0.001 0.999]\n",
      "observation-f:  [ 0.032  0.017 -0.031 -0.146]  pre update acts:  [0.995 0.005]  advantage used:  0.65  post update acts:  [0.998 0.002]\n",
      "observation-f:  [ 0.032 -0.178 -0.034  0.137]  pre update acts:  [0.004 0.996]  advantage used:  0.11  post update acts:  [0.003 0.997]\n",
      "observation-f:  [ 0.028  0.018 -0.032 -0.166]  pre update acts:  [0.999 0.001]  advantage used:  -0.24  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.029 -0.177 -0.035  0.116]  pre update acts:  [0.006 0.994]  advantage used:  0.7  post update acts:  [0.004 0.996]\n",
      "observation-f:  [ 0.025  0.019 -0.033 -0.187]  pre update acts:  [1. 0.]  advantage used:  -0.17  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.026 -0.176 -0.036  0.095]  pre update acts:  [0.009 0.991]  advantage used:  -0.48  post update acts:  [0.012 0.988]\n",
      "observation-f:  [ 0.022  0.02  -0.035 -0.209]  pre update acts:  [1. 0.]  advantage used:  0.7  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.022 -0.175 -0.039  0.073]  pre update acts:  [0.021 0.979]  advantage used:  -0.15  post update acts:  [0.027 0.973]\n",
      "observation-f:  [ 0.019  0.021 -0.037 -0.232]  pre update acts:  [1. 0.]  advantage used:  -0.69  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.019 -0.174 -0.042  0.049]  pre update acts:  [0.069 0.931]  advantage used:  0.82  post update acts:  [0.014 0.986]\n",
      "observation-f:  [ 0.016  0.022 -0.041 -0.257]  pre update acts:  [1. 0.]  advantage used:  -0.37  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.016 -0.172 -0.046  0.022]  pre update acts:  [0.047 0.953]  advantage used:  -0.7  post update acts:  [0.979 0.021]\n",
      "observation-f:  [ 0.013  0.023 -0.046 -0.284]  pre update acts:  [1. 0.]  advantage used:  0.6  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.013 -0.171 -0.051 -0.006]  pre update acts:  [0.207 0.793]  advantage used:  0.91  post update acts:  [0.995 0.005]\n",
      "observation-f:  [ 0.01  -0.365 -0.051  0.27 ]  pre update acts:  [0.006 0.994]  advantage used:  -1.2  post update acts:  [1. 0.]\n",
      "observation-f:  [ 0.003 -0.17  -0.046 -0.039]  pre update acts:  [0.999 0.001]  advantage used:  0.58  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.001 -0.364 -0.047  0.239]  pre update acts:  [0.02 0.98]  advantage used:  -0.56  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.008 -0.168 -0.042 -0.068]  pre update acts:  [1. 0.]  advantage used:  0.02  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.011 -0.363 -0.043  0.211]  pre update acts:  [1. 0.]  advantage used:  -0.2  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.019 -0.167 -0.039 -0.095]  pre update acts:  [1. 0.]  advantage used:  -0.01  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.022 -0.362 -0.041  0.185]  pre update acts:  [1. 0.]  advantage used:  0.23  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.029 -0.166 -0.037 -0.12 ]  pre update acts:  [1. 0.]  advantage used:  -0.11  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.033 -0.36  -0.04   0.16 ]  pre update acts:  [1. 0.]  advantage used:  0.18  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.04  -0.165 -0.037 -0.145]  pre update acts:  [1. 0.]  advantage used:  0.24  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.043 -0.359 -0.039  0.136]  pre update acts:  [1. 0.]  advantage used:  -0.06  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.05  -0.164 -0.037 -0.169]  pre update acts:  [1. 0.]  advantage used:  0.26  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.054 -0.358 -0.04   0.112]  pre update acts:  [1. 0.]  advantage used:  0.29  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.061 -0.163 -0.038 -0.193]  pre update acts:  [1. 0.]  advantage used:  -0.08  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.064 -0.357 -0.042  0.088]  pre update acts:  [1. 0.]  advantage used:  0.36  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.071 -0.552 -0.04   0.367]  pre update acts:  [1. 0.]  advantage used:  -0.69  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.082 -0.356 -0.033  0.062]  pre update acts:  [1. 0.]  advantage used:  0.52  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.089 -0.551 -0.031  0.344]  pre update acts:  [1. 0.]  advantage used:  -0.28  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.1   -0.355 -0.024  0.042]  pre update acts:  [1. 0.]  advantage used:  0.19  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.107 -0.55  -0.024  0.327]  pre update acts:  [1. 0.]  advantage used:  0.21  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.118 -0.354 -0.017  0.027]  pre update acts:  [1. 0.]  advantage used:  0.16  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.125 -0.549 -0.017  0.314]  pre update acts:  [1. 0.]  advantage used:  0.43  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.136 -0.354 -0.01   0.016]  pre update acts:  [1. 0.]  advantage used:  0.07  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.144 -0.549 -0.01   0.305]  pre update acts:  [1. 0.]  advantage used:  0.27  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.155 -0.354 -0.004  0.01 ]  pre update acts:  [1. 0.]  advantage used:  0.33  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.162 -0.549 -0.004  0.301]  pre update acts:  [1. 0.]  advantage used:  0.03  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.173 -0.354  0.002  0.007]  pre update acts:  [1. 0.]  advantage used:  0.41  post update acts:  [1. 0.]\n",
      "observation-f:  [-0.18  -0.549  0.002  0.301]  pre update acts:  [1. 0.]  advantage used:  0.39  post update acts:  [0.999 0.001]\n",
      "observation-f:  [-0.191 -0.354  0.008  0.009]  pre update acts:  [1. 0.]  advantage used:  0.15  post update acts:  [0.991 0.009]\n",
      "observation-f:  [-0.198 -0.549  0.009  0.304]  pre update acts:  [1. 0.]  advantage used:  0.31  post update acts:  [0.999 0.001]\n",
      "observation-f:  [-0.209 -0.354  0.015  0.014]  pre update acts:  [0.987 0.013]  advantage used:  0.18  post update acts:  [0.49 0.51]\n",
      "observation-f:  [-0.216 -0.549  0.015  0.311]  pre update acts:  [0.999 0.001]  advantage used:  0.3  post update acts:  [0.385 0.615]\n",
      "observation-f:  [-0.227 -0.354  0.021  0.024]  pre update acts:  [0.981 0.019]  advantage used:  0.25  post update acts:  [0.404 0.596]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4147/864264266.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enter test rotine  \\n 0 - no restriction run \\n 1 - randomized exploration \\n 2 - run with restrictions \\n 3 - expl lead by teacher ANN : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#main(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#main(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4147/3940408831.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ctr_l)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mobservation_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mobservation_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_reshaped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0maction_probs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1745\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3121\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    com=int(input(\"enter test rotine  \\n 0 - no restriction run \\n 1 - randomized exploration \\n 2 - run with restrictions \\n 3 - expl lead by teacher ANN : \"))\n",
    "    main(com)\n",
    "    #main(1)\n",
    "    #main(2)\n",
    "    #main(3)\n",
    "    #add for all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97840e7-0855-4c22-8162-c0210f85c9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
